{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b7ae17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.27.229.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafa1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efec988",
   "metadata": {},
   "source": [
    "# 라이브러리\n",
    "- 주요 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ea9e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pyspark \n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(sns.__version__)\n",
    "print(sklearn.__version__)\n",
    "\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04af4d",
   "metadata": {},
   "source": [
    "코드셀에서 마크다운으로 변환하는 단축키 ESC + M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0b014",
   "metadata": {},
   "source": [
    "## Spark 세션 만들기 (평가1)\n",
    "- master:\"local[1]\"\n",
    "- appName : my1stSpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31fe981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.27.229.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>my1stSpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd95f8b1370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"my1stSpark\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b31d9e",
   "metadata": {},
   "source": [
    "## RDD의 작동원리\n",
    "- 데이터 --> Transformation 메서드 활용 (lambda 함수 활용) --> Action 메서드 활용\n",
    "- PairRDD : 값이 Dictionary + 튜플처럼 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca97e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dict = {\n",
    "    \"name\" : [\"A\", \"B\", \"C\"]\n",
    "}\n",
    "\n",
    "temp_dict[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac33d9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_tuple = (1, 2, 3, 4)\n",
    "temp_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14482e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 10),\n",
       " ('javascript', 5),\n",
       " ('JAVA', 20),\n",
       " ('python', 5),\n",
       " ('R', 5),\n",
       " ('JAVA', 10)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프로그래밍 수강생 조사\n",
    "data = [('python', 10), ('javascript', 5), ('JAVA', 20), ('python', 5), ('R', 5), ('JAVA', 10)]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54781ec8",
   "metadata": {},
   "source": [
    "## PairRDD 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ebe82b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[1] at readRDDFromFile at PythonRDD.scala:274\n",
      "<class 'pyspark.rdd.RDD'>\n",
      "[('python', 10), ('javascript', 5), ('JAVA', 20), ('python', 5), ('R', 5), ('JAVA', 10)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 8) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "regi_lan = spark.sparkContext.parallelize(data)\n",
    "print(regi_lan)\n",
    "print(type(regi_lan))\n",
    "\n",
    "# Action Method\n",
    "print(regi_lan.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cee883",
   "metadata": {},
   "source": [
    "## PairRDD 메서드 종류\n",
    "- 참조 : https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740efe6",
   "metadata": {},
   "source": [
    "### groupbyKey()\n",
    "- 참조 : https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.groupByKey.html#pyspark.RDD.groupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "134a61ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python --> [10, 5]\n",
      "R --> [5]\n",
      "javascript --> [5]\n",
      "JAVA --> [20, 10]\n"
     ]
    }
   ],
   "source": [
    "group_rdd = regi_lan.groupByKey().collect()\n",
    "for keys, values in group_rdd:\n",
    "    print(keys, \"-->\", list(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "051aa854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JAVA', 2), ('R', 1), ('javascript', 1), ('python', 2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(regi_lan.groupByKey().mapValues(len).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0a324f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JAVA', [20, 10]), ('R', [5]), ('javascript', [5]), ('python', [10, 5])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(regi_lan.groupByKey().mapValues(list).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d973d9",
   "metadata": {},
   "source": [
    "### sortByKey()\n",
    "- 참조 : https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.sortByKey.html?highlight=sortbykey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "648ebd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('JAVA', 20), ('JAVA', 10), ('R', 5), ('javascript', 5), ('python', 10), ('python', 5)]\n"
     ]
    }
   ],
   "source": [
    "print(regi_lan.sortByKey().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0bb346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('python', 10), ('python', 5), ('javascript', 5), ('R', 5), ('JAVA', 20), ('JAVA', 10)]\n"
     ]
    }
   ],
   "source": [
    "print(regi_lan.sortByKey(ascending=False).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20027b2e",
   "metadata": {},
   "source": [
    "### reduceByKey()\n",
    "- 사칙연산\n",
    "- lambda 함수 사용 필요\n",
    "- 참조 : https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.reduceByKey.html?highlight=reducebykey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eba687e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 15), ('R', 5), ('javascript', 5), ('JAVA', 30)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regi_lan.reduceByKey(lambda x1, x2 : x1 + x2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6242d824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 5), ('R', 5), ('javascript', 5), ('JAVA', 10)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regi_lan.reduceByKey(lambda x1, x2 : x1 - x2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac035403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 50), ('R', 5), ('javascript', 5), ('JAVA', 200)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regi_lan.reduceByKey(lambda x1, x2 : x1 * x2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0266242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python', 2.0), ('R', 5), ('javascript', 5), ('JAVA', 2.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/08 10:26:38 WARN JavaUtils: Attempt to delete using native Unix OS command failed for path = /tmp/blockmgr-fbcc4e54-32c3-4a40-82cd-5c29bb066865. Falling back to Java IO way\n",
      "java.io.IOException: Failed to delete: /tmp/blockmgr-fbcc4e54-32c3-4a40-82cd-5c29bb066865\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingUnixNative(JavaUtils.java:171)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:110)\n",
      "\tat org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)\n",
      "\tat org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1193)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1(DiskBlockManager.scala:318)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$doStop$1$adapted(DiskBlockManager.scala:314)\n",
      "\tat scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1323)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.doStop(DiskBlockManager.scala:314)\n",
      "\tat org.apache.spark.storage.DiskBlockManager.$anonfun$addShutdownHook$2(DiskBlockManager.scala:296)\n",
      "\tat org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat scala.util.Try$.apply(Try.scala:210)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)\n",
      "\tat org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "regi_lan.reduceByKey(lambda x1, x2 : x1 / x2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88448365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
